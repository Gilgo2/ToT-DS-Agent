{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import pandas as pd\n",
    "import langchain_core\n",
    "from langchain.globals import set_verbose, set_debug\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import seaborn as sns\n",
    "import inspect\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import traceback\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from treelib import Node, Tree  #  moved here to prevent bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AutoKaggle Project\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"XXXXXXXXXXXXXXXXXXXXXXXXXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-proj-XXXX'\n",
    "os.environ[\"OPENAI_ORGANIZATION\"] = 'org-XXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Prompts folder\n",
    "import os\n",
    "prompt_path = './prompts/flow_prompts'\n",
    "prompts = []\n",
    "for filename in os.listdir(prompt_path):\n",
    "    if '.txt' not in filename:\n",
    "        continue\n",
    "    with open(os.path.join(prompt_path, filename)) as prompt_f:\n",
    "        prompt = prompt_f.read()\n",
    "    prompts.append(prompt)\n",
    "with open(os.path.join(prompt_path, 'titanic_prompt.txt')) as prompt_f:\n",
    "    titanic_info = prompt_f.read()\n",
    "with open(os.path.join(prompt_path, 'houses_prompt.txt')) as prompt_f:\n",
    "    housing_info = prompt_f.read()\n",
    "dataset_info = {'titanic': titanic_info, 'housing':housing_info}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxRetriesExceededError(Exception):\n",
    "    pass\n",
    "class MissingCodeValidationException(Exception):\n",
    "    pass\n",
    "\n",
    "class FailedGeneratingFunction(Exception):\n",
    "    pass\n",
    "class MissingFunctionBoundaries(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataFrameValidationException(Exception):\n",
    "    pass\n",
    "\n",
    "class PandasColumnsIntegerValidationException(Exception):\n",
    "    pass\n",
    "class TargetFeatureInDataFrameValidationException(Exception):\n",
    "    pass\n",
    "class TargetFeatureIsBinaryValidationException(Exception):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictInModelObjectValidationException(Exception):\n",
    "    pass\n",
    "class CheckFittedValidationException(Exception):\n",
    "    pass\n",
    "class FunctionDoesNotMatchSignatureValidationException(Exception):\n",
    "    pass\n",
    "class ModelIsPipelineValidationException(Exception):\n",
    "    pass\n",
    "def check_model_is_not_pipeline(model):\n",
    "    try:\n",
    "        assert type(model) != sklearn.pipeline.Pipeline\n",
    "    except:\n",
    "        raise ModelIsPipelineValidationException(\"Returned model should not be a pipeline\")\n",
    "def predict_in_model_object(model):\n",
    "    try:\n",
    "        assert 'predict' in dir(model)\n",
    "    except:\n",
    "        raise PredictInModelObjectValidationException(\"Returned object is not a classifier\")\n",
    "def check_fitted(model): \n",
    "    try:\n",
    "        assert hasattr(model, \"classes_\")\n",
    "    except:\n",
    "        raise CheckFittedValidationException(\"Returned object was not fitted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_prevent_babbling(llm, prompt):\n",
    "    chunks = []\n",
    "    min_characters = 100\n",
    "    char_count = 0\n",
    "    print(f\"------PROMPT-------:\\n {prompt} \\n -------------\")\n",
    "    for chunk in llm.stream(prompt):\n",
    "        if type(chunk) != str:\n",
    "            chunk = chunk.content\n",
    "        char_count += len(chunk)\n",
    "        #print(chunk, end=\"\", flush=True)\n",
    "        # We stop the model when it begings babbling, usually marked by the <|end_header_id|> token.\n",
    "        if '<|end_header_id|>' in chunk and char_count > min_characters:\n",
    "            break\n",
    "        chunks.append(chunk)\n",
    "    return \"\".join(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsing_regex = {\"llama3\":\"```(?:[Pp]ython)?\\n([^`]+?)```\",\n",
    "                \"openai\": \"(def.*)\"\n",
    "                }\n",
    "SELF_DEBUG_PROMPT = \"I received the error for your last code block {}: {}. Can you regenerate the code?\"\n",
    "OUTPUT_VARIABLE_PROMPT = \".\\nCall your function and save it to a variable named {}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AutoKaggleCoT:\n",
    "    def __init__(self, llm, llm_type, dataset_name, dataset, dataset_info,\n",
    "                 init_template, target_feature, metric,\n",
    "                 max_self_debug_attempts=3, max_retry_attempts=10): #llm_type\n",
    "        self.init_template = f\"\"\"Hello, today your job is to be a data scientist assistant for classic ML problems. \n",
    "                            You will provide working functions that can be executed with no required changes.\n",
    "                            Try to be creative in your code.\n",
    "                            dataset info:\n",
    "                            {dataset_info}\n",
    "                            \n",
    "                            New Task:\n",
    "                            \"\"\"\n",
    "        self.llm = llm\n",
    "        self.llm_type = llm_type\n",
    "        self.pdf = dataset\n",
    "        self.metric = metric\n",
    "        self.max_self_debug_attempts = max_self_debug_attempts\n",
    "        self.max_retry_attempts = max_retry_attempts\n",
    "        self.target_feature = target_feature\n",
    "        results_dict[llm_type] = {} \n",
    "\n",
    "    def pandas_dataframe_validation(self, pdf):\n",
    "        try:\n",
    "            assert type(pdf) == pd.DataFrame\n",
    "        except:\n",
    "            raise PandasDataFrameValidationException(\"Function output is not a pandas dataframe\")\n",
    "    def pandas_columns_integers_validation(self, pdf):\n",
    "        try:\n",
    "            pdf.astype(int)\n",
    "        except:\n",
    "            raise PandasColumnsIntegerValidationException(\"Not all the dataframe's columns are numerical\")\n",
    "    def target_feature_in_dataframe(self, pdf):\n",
    "        try:\n",
    "            assert self.target_feature in pdf.columns.tolist()\n",
    "        except:\n",
    "            raise TargetFeatureInDataFrameValidationException(f\"Target feature '{self.target_feature}' is not in the dataframe\")\n",
    "    def target_feature_is_binary(self, pdf):\n",
    "        try:\n",
    "            assert pdf[self.target_feature].tolist() == original_value\n",
    "        except:\n",
    "            raise TargetFeatureIsBinaryValidationException(f\"Target feature '{self.target_feature}' was altered\")\n",
    "\n",
    "    def read_prompt(self, prompt_name):\n",
    "        with open(f'./prompts/flow_prompts/{prompt_name}.txt', 'r') as prompt_file:\n",
    "            return prompt_file.read()\n",
    "        \n",
    "    def predict_prompt_and_parse(self, prompt):\n",
    "        \n",
    "        res = prediction_prevent_babbling(self.llm, prompt)\n",
    "        if '```' in res:\n",
    "            regex = parsing_regex['llama3']\n",
    "        else:\n",
    "            regex = parsing_regex['openai']\n",
    "        code_blocks = re.findall(regex, res, flags=re.DOTALL)\n",
    "        return code_blocks\n",
    "\n",
    "        \n",
    "    def execute_code(self, code_blocks, output_variable_name, **input_variables):\n",
    "        ldic = locals()\n",
    "        for variable_name, variable_value in input_variables.items():\n",
    "            globals()[variable_name] = variable_value\n",
    "        for code in code_blocks:\n",
    "            print(\"-------------Executing\", code)\n",
    "            exec(code, globals())    \n",
    "        \n",
    "        return eval(output_variable_name)\n",
    "\n",
    "    def manage_error(self, error_count, retry_attempts, code_blocks, e, step_prompt):\n",
    "        error_count += 1\n",
    "        if error_count >= self.max_self_debug_attempts:\n",
    "            print(\"Failed self debug\",)\n",
    "            prompt = step_prompt\n",
    "            retry_attempts += 1\n",
    "            error_count = 0\n",
    "            print(\"Retry attempt: \", retry_attempts)\n",
    "            if retry_attempts > self.max_retry_attempts:\n",
    "                raise MaxRetriesExceededError()\n",
    "        else:\n",
    "            #prompt = SELF_DEBUG_PROMPT.format(code_blocks, e)\n",
    "            prompt = f\"History: {step_prompt}, you gave me {code_blocks}. I got the error {type(e)}:{e}, can you fix it?\"\n",
    "        return prompt, error_count, retry_attempts\n",
    "\n",
    "    def validate_step(self,step_output, step_validations):\n",
    "        for validation in step_validations:\n",
    "            validation(step_output)\n",
    "            \n",
    "    def run_step(self, step_prompt, step_name, output_variable_name, step_validations = None, **input_variables):\n",
    "               \n",
    "        completed = False\n",
    "        error_count = 0\n",
    "        retry_attempts = 0\n",
    "        prompt = step_prompt\n",
    "        results_dict[self.llm_type][step_name] = {'generation_error_count': 0, 'debug_error_count': 0}\n",
    "        while not completed:\n",
    "            code_blocks = self.predict_prompt_and_parse(self.init_template + prompt+ OUTPUT_VARIABLE_PROMPT.format(output_variable_name))  \n",
    "            \n",
    "            try:\n",
    "               # print(code_blocks)\n",
    "                if len(code_blocks) == 0:\n",
    "                    raise MissingCodeValidationException()\n",
    "                step_output = self.execute_code(code_blocks, output_variable_name, **input_variables)\n",
    "                if step_validations:\n",
    "                    self.validate_step(step_output, step_validations)\n",
    "            except Exception as e:\n",
    "                results_dict[self.llm_type][step_name][type(e).__name__] = results_dict[self.llm_type][step_name].get(type(e).__name__,0) + 1\n",
    "                print(\"Error:\", e, '---')\n",
    "                \n",
    "                if error_count == 0:\n",
    "                    results_dict[self.llm_type][step_name]['generation_error_count'] += 1\n",
    "                else:\n",
    "                    results_dict[self.llm_type][step_name]['debug_error_count'] += 1\n",
    "                prompt, error_count, retry_attempts = self.manage_error(error_count, retry_attempts, code_blocks, e, step_prompt)\n",
    "                    \n",
    "            else:\n",
    "                completed = True\n",
    "        return step_output\n",
    "\n",
    "    def llm_exploration(self, pdf):\n",
    "        self.exploration_string = self.run_step(self.read_prompt('exploration'), 'exploration', 'exploration_string')\n",
    "        print(\"Finished exploration\", self.exploration_string)\n",
    "        return self.exploration_string\n",
    "\n",
    "    def llm_preprocessing(self, exploration_string, pdf, target_feature):\n",
    "        self.preprocessed_data = self.run_step(self.read_prompt('data_preprocessing').format(exploration_string)\n",
    "                                               + '\\nreturn a pandas dataframe', 'preprocessing', 'preprocessed_data',\n",
    "                                               step_validations=[self.pandas_dataframe_validation, self.pandas_columns_integers_validation,\n",
    "                                                                self.target_feature_in_dataframe, self.target_feature_is_binary] ,pdf = pdf)\n",
    "        print(\"Finished preprocessing\")\n",
    "        X = self.preprocessed_data.drop(columns=[target_feature])\n",
    "        y = self.preprocessed_data[target_feature]\n",
    "        return X,y\n",
    "\n",
    "    def llm_training(self, X_train, y_train):\n",
    "        self.best_model = self.run_step(self.read_prompt('model_training'), 'training', 'best_model',\n",
    "                                        step_validations=[predict_in_model_object],\n",
    "                                        X_train=X_train, y_train=y_train)\n",
    "        print(\"Finished training\", self.best_model)\n",
    "        return self.best_model\n",
    "\n",
    "    def run(self):\n",
    "        exploration_string = self.llm_exploration(self.pdf)\n",
    "        X, y = self.llm_preprocessing(exploration_string, self.pdf, self.target_feature)       \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X,y,test_size=0.25, random_state=42)\n",
    "        best_model = self.llm_training(self.X_train, self.y_train)\n",
    "        print(f\"{self.evaluate(best_model, self.X_test, self.y_test)} accuracy score\")\n",
    "        results_dict[self.llm_type]['best_score'] = self.evaluate(best_model, self.X_test, self.y_test)\n",
    "    \n",
    "        \n",
    "        \n",
    "    def evaluate(self, llm_model, X_test, y_test):\n",
    "        if self.metric == 'classification':\n",
    "            y_pred = llm_model.predict(X_test)\n",
    "            model_score = accuracy_score(y_test, y_pred)\n",
    "            return model_score\n",
    "        else:\n",
    "            y_pred = llm_model.predict(X_test)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_type = 'codegemma'\n",
    "got_openai_api_access = False\n",
    "llms = None\n",
    "if got_openai_api_access:\n",
    "    llms = [('gpt-4o', ChatOpenAI(model='gpt-4o')), ('llama3', Ollama(model=llm_type)),\n",
    "           ('gpt-4-turbo', ChatOpenAI(model='gpt-4-turbo')), ('gpt-4', ChatOpenAI(model='gpt-4')),\n",
    "           ('gpt-3.5-turbo', ChatOpenAI(model='gpt-3.5-turbo'))]\n",
    "else:\n",
    "    llms = [('llama3', Ollama(model=llm_type))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------PROMPT-------:\n",
      " Hello, today your job is to be a data scientist assistant for classic ML problems. \n",
      "                            You will provide working functions that can be executed with no required changes.\n",
      "                            Try to be creative in your code.\n",
      "                            dataset info:\n",
      "                            This dataset title is:\n",
      "Titanic - Machine Learning from Disaster\n",
      "Size: 93.08 kB\n",
      "Data Dictionary\n",
      "Variable\tDefinition\tKey         Feature Type\n",
      "Survived\tSurvived\t0 = No, 1 = Yes         Number\n",
      "Pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd       Number\n",
      "Sex\tSex                                             String\n",
      "Name    Name of the passenger, may also contain a title String\n",
      "Age\tAge in years                                    Number\n",
      "Sibsp\t# of siblings / spouses aboard the Titanic      Number\n",
      "Parch\t# of parents / children aboard the Titanic      Number\n",
      "Ticket\tTicket number                                   Number\n",
      "Fare\tPassenger fare                                  Number\n",
      "Cabin\tCabin number                                    String\n",
      "Embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
      "Variable Notes\n",
      "Pclass: A proxy for socio-economic status (SES)\n",
      "1st = Upper\n",
      "2nd = Middle\n",
      "3rd = Lower\n",
      "Age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
      "Sibsp: The dataset defines family relations in this way...\n",
      "Sibling = brother, sister, stepbrother, stepsister\n",
      "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
      "Parch: The dataset defines family relations in this way...\n",
      "Parent = mother, father\n",
      "Child = daughter, son, stepdaughter, stepson\n",
      "Some children travelled only with a nanny, therefore parch=0 for them.\n",
      "I have already loaded this data into a pandas dataframe named pdf.\n",
      "This is a classification problem to predict surival on the Titanic.\n",
      "                            \n",
      "                            New Task:\n",
      "                            Please provide a function that receives a dataframe named pdf and returns a string that explains each variable.\n",
      "The function should do  Data Exploration and Understanding:\n",
      "Explore the dataset's structure, features, and target variable.\n",
      "Understand the distribution of features and the target variable.\n",
      "Identify any missing or erroneous data.\n",
      "The function should have no prints and return a string summary output.\n",
      "Identify all categorial and numerical features\n",
      "Call the function and save all output it into a variable named exploration_string\n",
      ".\n",
      "Call your function and save it to a variable named exploration_string \n",
      " -------------\n",
      "-------------Executing import pandas as pd\n",
      "\n",
      "def data_exploration(pdf):\n",
      "    \"\"\"\n",
      "    Returns a string summary of the dataset's structure, features, and target variable.\n",
      "\n",
      "    Args:\n",
      "        pdf: A pandas dataframe.\n",
      "\n",
      "    Returns:\n",
      "        A string summary of the dataset.\n",
      "    \"\"\"\n",
      "\n",
      "    # Data Structure\n",
      "    data_structure = f\"Number of rows: {pdf.shape[0]}, Number of columns: {pdf.shape[1]}\"\n",
      "\n",
      "    # Features and Target Variable\n",
      "    features = \", \".join(pdf.columns)\n",
      "    target_variable = \"Survived\"\n",
      "\n",
      "    # Feature Types\n",
      "    categorical_features = list(pdf.select_dtypes(include=[\"object\"]).columns)\n",
      "    numerical_features = list(pdf.select_dtypes(include=[\"int64\", \"float64\"]).columns)\n",
      "\n",
      "    # Data Distribution\n",
      "    feature_distributions = pdf.describe()\n",
      "\n",
      "    # Missing Data\n",
      "    missing_data = pdf.isnull().sum().sort_values(ascending=False)\n",
      "\n",
      "    # Erroneous Data\n",
      "    erroneous_data = pdf.loc[pdf[\"Age\"] > 100].shape[0]\n",
      "\n",
      "    # Output\n",
      "    return f\"\"\"\n",
      "Data Structure:\n",
      "{data_structure}\n",
      "\n",
      "Features:\n",
      "{features}\n",
      "\n",
      "Target Variable:\n",
      "{target_variable}\n",
      "\n",
      "Feature Types:\n",
      "Categorical Features: {categorical_features}\n",
      "Numerical Features: {numerical_features}\n",
      "\n",
      "Data Distribution:\n",
      "{feature_distributions}\n",
      "\n",
      "Missing Data:\n",
      "{missing_data}\n",
      "\n",
      "Erroneous Data:\n",
      "{erroneous_data}\n",
      "\"\"\"\n",
      "\n",
      "# Call the function\n",
      "exploration_string = data_exploration(pdf)\n",
      "\n",
      "# Print the output\n",
      "print(exploration_string)\n",
      "\n",
      "\n",
      "Data Structure:\n",
      "Number of rows: 891, Number of columns: 12\n",
      "\n",
      "Features:\n",
      "PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      "\n",
      "Target Variable:\n",
      "Survived\n",
      "\n",
      "Feature Types:\n",
      "Categorical Features: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "Numerical Features: ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "\n",
      "Data Distribution:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Missing Data:\n",
      "Cabin          687\n",
      "Age            177\n",
      "Embarked         2\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "dtype: int64\n",
      "\n",
      "Erroneous Data:\n",
      "0\n",
      "\n",
      "Finished exploration \n",
      "Data Structure:\n",
      "Number of rows: 891, Number of columns: 12\n",
      "\n",
      "Features:\n",
      "PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      "\n",
      "Target Variable:\n",
      "Survived\n",
      "\n",
      "Feature Types:\n",
      "Categorical Features: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "Numerical Features: ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "\n",
      "Data Distribution:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Missing Data:\n",
      "Cabin          687\n",
      "Age            177\n",
      "Embarked         2\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "dtype: int64\n",
      "\n",
      "Erroneous Data:\n",
      "0\n",
      "\n",
      "------PROMPT-------:\n",
      " Hello, today your job is to be a data scientist assistant for classic ML problems. \n",
      "                            You will provide working functions that can be executed with no required changes.\n",
      "                            Try to be creative in your code.\n",
      "                            dataset info:\n",
      "                            This dataset title is:\n",
      "Titanic - Machine Learning from Disaster\n",
      "Size: 93.08 kB\n",
      "Data Dictionary\n",
      "Variable\tDefinition\tKey         Feature Type\n",
      "Survived\tSurvived\t0 = No, 1 = Yes         Number\n",
      "Pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd       Number\n",
      "Sex\tSex                                             String\n",
      "Name    Name of the passenger, may also contain a title String\n",
      "Age\tAge in years                                    Number\n",
      "Sibsp\t# of siblings / spouses aboard the Titanic      Number\n",
      "Parch\t# of parents / children aboard the Titanic      Number\n",
      "Ticket\tTicket number                                   Number\n",
      "Fare\tPassenger fare                                  Number\n",
      "Cabin\tCabin number                                    String\n",
      "Embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
      "Variable Notes\n",
      "Pclass: A proxy for socio-economic status (SES)\n",
      "1st = Upper\n",
      "2nd = Middle\n",
      "3rd = Lower\n",
      "Age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
      "Sibsp: The dataset defines family relations in this way...\n",
      "Sibling = brother, sister, stepbrother, stepsister\n",
      "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
      "Parch: The dataset defines family relations in this way...\n",
      "Parent = mother, father\n",
      "Child = daughter, son, stepdaughter, stepson\n",
      "Some children travelled only with a nanny, therefore parch=0 for them.\n",
      "I have already loaded this data into a pandas dataframe named pdf.\n",
      "This is a classification problem to predict surival on the Titanic.\n",
      "                            \n",
      "                            New Task:\n",
      "                            You have a dataset loaded into a pandas dataframe named pdf.\n",
      "Do not read a file!\n",
      "Given this exploration string \n",
      "Data Structure:\n",
      "Number of rows: 891, Number of columns: 12\n",
      "\n",
      "Features:\n",
      "PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked\n",
      "\n",
      "Target Variable:\n",
      "Survived\n",
      "\n",
      "Feature Types:\n",
      "Categorical Features: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "Numerical Features: ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "\n",
      "Data Distribution:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "Missing Data:\n",
      "Cabin          687\n",
      "Age            177\n",
      "Embarked         2\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "dtype: int64\n",
      "\n",
      "Erroneous Data:\n",
      "0\n",
      ":\n",
      "1. Handle missing data.\n",
      "2. Use the exploration string for feature engineering to improve the model.\n",
      "3. You must encode all categorical variables into numerical format, remove the categorical variables.\n",
      "4. Scale or normalize numerical features to a similar scale to prevent dominance by certain features.\n",
      "5. The column 'SalePrice' is the target feature, do not destroy it.\n",
      "return a pandas dataframe.\n",
      "Call your function and save it to a variable named preprocessed_data \n",
      " -------------\n",
      "-------------Executing import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "\n",
      "def preprocess_data(pdf):\n",
      "    # Handle missing data\n",
      "    pdf['Cabin'].fillna('Missing', inplace=True)\n",
      "    pdf['Age'].fillna(pdf['Age'].median(), inplace=True)\n",
      "    pdf['Embarked'].fillna('S', inplace=True)\n",
      "\n",
      "    # Encode categorical variables\n",
      "    pdf = pd.get_dummies(pdf, columns=['Sex', 'Embarked'])\n",
      "\n",
      "    # Scale numerical features\n",
      "    scaler = StandardScaler()\n",
      "    pdf[['Age', 'SibSp', 'Parch', 'Fare']] = scaler.fit_transform(pdf[['Age', 'SibSp', 'Parch', 'Fare']])\n",
      "\n",
      "    # Remove categorical variables\n",
      "    pdf.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
      "\n",
      "    return pdf\n",
      "\n",
      "-------------Executing preprocessed_data = preprocess_data(pdf)\n",
      "\n",
      "Finished preprocessing\n",
      "------PROMPT-------:\n",
      " Hello, today your job is to be a data scientist assistant for classic ML problems. \n",
      "                            You will provide working functions that can be executed with no required changes.\n",
      "                            Try to be creative in your code.\n",
      "                            dataset info:\n",
      "                            This dataset title is:\n",
      "Titanic - Machine Learning from Disaster\n",
      "Size: 93.08 kB\n",
      "Data Dictionary\n",
      "Variable\tDefinition\tKey         Feature Type\n",
      "Survived\tSurvived\t0 = No, 1 = Yes         Number\n",
      "Pclass\tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd       Number\n",
      "Sex\tSex                                             String\n",
      "Name    Name of the passenger, may also contain a title String\n",
      "Age\tAge in years                                    Number\n",
      "Sibsp\t# of siblings / spouses aboard the Titanic      Number\n",
      "Parch\t# of parents / children aboard the Titanic      Number\n",
      "Ticket\tTicket number                                   Number\n",
      "Fare\tPassenger fare                                  Number\n",
      "Cabin\tCabin number                                    String\n",
      "Embarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n",
      "Variable Notes\n",
      "Pclass: A proxy for socio-economic status (SES)\n",
      "1st = Upper\n",
      "2nd = Middle\n",
      "3rd = Lower\n",
      "Age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
      "Sibsp: The dataset defines family relations in this way...\n",
      "Sibling = brother, sister, stepbrother, stepsister\n",
      "Spouse = husband, wife (mistresses and fiancÃ©s were ignored)\n",
      "Parch: The dataset defines family relations in this way...\n",
      "Parent = mother, father\n",
      "Child = daughter, son, stepdaughter, stepson\n",
      "Some children travelled only with a nanny, therefore parch=0 for them.\n",
      "I have already loaded this data into a pandas dataframe named pdf.\n",
      "This is a classification problem to predict surival on the Titanic.\n",
      "                            \n",
      "                            New Task:\n",
      "                            Now we move to Model Training:\n",
      "Training the selected machine learning models using the training dataset.\n",
      "Tuning hyperparameters to optimize model performance.\n",
      "Employing techniques like cross-validation to assess model generalization and prevent overfitting.\n",
      "Evaluating model performance on the validation set using appropriate metrics such as accuracy, precision, recall, F1-score, etc.\n",
      "The dataframe is already split into X_train, X_test, y_train, y_test. \n",
      "Please write a function that receives X_train, y_train. \n",
      "The function trains all models using some gridsearch with different hyperparameters. \n",
      "The function should return an object of the best model..\n",
      "Call your function and save it to a variable named best_model \n",
      " -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Executing from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.model_selection import GridSearchCV\n",
      "\n",
      "def find_best_model(X_train, y_train):\n",
      "    # Define models\n",
      "    models = {\n",
      "        'RandomForestClassifier': RandomForestClassifier(),\n",
      "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
      "        'SVC': SVC(),\n",
      "        'LogisticRegression': LogisticRegression()\n",
      "    }\n",
      "\n",
      "    # Define hyperparameter grids\n",
      "    hyperparameter_grids = {\n",
      "        'RandomForestClassifier': {\n",
      "            'n_estimators': [100, 200, 300],\n",
      "            'max_depth': [None, 10, 20, 30],\n",
      "            'min_samples_split': [2, 5, 10]\n",
      "        },\n",
      "        'GradientBoostingClassifier': {\n",
      "            'n_estimators': [100, 200, 300],\n",
      "            'learning_rate': [0.01, 0.1, 0.3],\n",
      "            'subsample': [0.4, 0.7, 1.0]\n",
      "        },\n",
      "        'SVC': {\n",
      "            'C': [0.1, 1.0, 10.0],\n",
      "            'kernel': ['rbf', 'sigmoid'],\n",
      "            'gamma': [0.1, 1.0, 10.0]\n",
      "        },\n",
      "        'LogisticRegression': {\n",
      "            'C': [0.1, 1.0, 10.0],\n",
      "            'penalty': ['l1', 'l2'],\n",
      "            'solver': ['lbfgs']\n",
      "        }\n",
      "    }\n",
      "\n",
      "    # Perform grid search for each model\n",
      "    best_models = {}\n",
      "    for model_name, model in models.items():\n",
      "        grid_search = GridSearchCV(estimator=model, param_grid=hyperparameter_grids[model_name], cv=5)\n",
      "        grid_search.fit(X_train, y_train)\n",
      "        best_models[model_name] = grid_search.best_estimator_\n",
      "\n",
      "    # Return the best model\n",
      "    return best_models['RandomForestClassifier']\n",
      "\n",
      "# Call the function and save the best model\n",
      "best_model = find_best_model(X_train, y_train)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training RandomForestClassifier(max_depth=20, min_samples_split=10)\n",
      "0.4073319070625462 accuracy score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan 0.79188643        nan 0.79487151        nan 0.79033778]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Inbar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}  #  define this before using it.\n",
    "\n",
    "\n",
    "def get_dataset():\n",
    "    try:\n",
    "        dataset_name = 'housing'\n",
    "        target_feature = 'SalePrice'\n",
    "        pdf = pd.read_csv('./data/house-prices-advanced-regression-techniques/train.csv')  #  note: the file doesn't exist in the repo.\n",
    "        return (dataset_name, target_feature, pdf)\n",
    "    except:\n",
    "        # a fallback I added to be able to test the code without the file.\n",
    "        dataset_name = 'titanic'\n",
    "        target_feature = 'Survived'\n",
    "        pdf = pd.read_csv('./data/titanic/train.csv')  #  I assume this works the same way.\n",
    "        return (dataset_name, target_feature, pdf)\n",
    "\n",
    "\n",
    "for llm_type, llm in llms:\n",
    "    pdf = None\n",
    "    dataset_name, target_feature, pdf = get_dataset()\n",
    "    original_value = pdf[target_feature].tolist()\n",
    "    pdf_temp = pdf.copy()\n",
    "    AK = None\n",
    "    try:\n",
    "        AK = AutoKaggleCoT(llm, llm_type, dataset_name, pdf_temp, dataset_info[dataset_name], init_template, target_feature = target_feature, metric='regression', max_self_debug_attempts=3, max_retry_attempts=12)\n",
    "    except:\n",
    "        AK = AutoKaggleCoT(llm, llm_type, dataset_name, pdf_temp, dataset_info[dataset_name], '???', target_feature = target_feature, metric='regression', max_self_debug_attempts=3, max_retry_attempts=12)\n",
    "    AK.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llama3': {'exploration': {'generation_error_count': 0,\n",
       "   'debug_error_count': 0},\n",
       "  'preprocessing': {'generation_error_count': 0, 'debug_error_count': 0},\n",
       "  'training': {'generation_error_count': 0, 'debug_error_count': 0},\n",
       "  'best_score': 0.4073319070625462}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "BFS = 0\n",
    "DFS = 1\n",
    "class AutoKaggleToT:\n",
    "    def __init__(self, llm, llm_type, dataset_name, dataset, dataset_info, target_feature, metric, max_self_debug_attempts=3,\n",
    "                 max_retry_attempts=3, child_count=3, tree_scan_method=BFS): #llm_type\n",
    "        self.llm = llm\n",
    "        self.pdf = dataset\n",
    "        self.metric = metric\n",
    "        self.max_self_debug_attempts = max_self_debug_attempts\n",
    "        self.max_retry_attempts = max_retry_attempts\n",
    "        self.target_feature = target_feature\n",
    "        self.child_count = child_count\n",
    "        self.dataset_name = dataset_name\n",
    "        if dataset_name not in results_tree:\n",
    "            results_tree.create_node(dataset_name, dataset_name, parent='root')\n",
    "        self.base_parent_name = f\"{self.dataset_name}: {llm_type}: {self.max_self_debug_attempts}, {max_retry_attempts}, {child_count}\"            \n",
    "        results_tree.create_node(self.base_parent_name, self.base_parent_name, parent=dataset_name)\n",
    "        self.init_template = f\"\"\"Hello, today your job is to be a data scientist assistant for classic ML problems. \n",
    "                                You will provide functions that can be executed with no required changes.\n",
    "                                We will be working in a tree of thought manner, In each step I want you to suggest {child_count} different functions.\n",
    "                                The functions should be named function_1, ..., function_{self.child_count}\n",
    "                                Be creative in your solutions the functions need to be complex.\n",
    "                                Each function should be indpendent and a full solution to the task given.\n",
    "                                We will then try to execute them and debug each function separately.\n",
    "                                dataset info:\n",
    "                                {dataset_info}\n",
    "                                \n",
    "                                New Task:\n",
    "                                \"\"\"\n",
    "                \n",
    "        self.metric = metric\n",
    "\n",
    "    def read_prompt(self, prompt_name):\n",
    "        with open(f'./prompts/flow_prompts/tot_prompts/{prompt_name}.txt', 'r') as prompt_file:\n",
    "            return prompt_file.read()\n",
    "        \n",
    "    def predict_prompt_and_parse(self, prompt):\n",
    "        \n",
    "        res = prediction_prevent_babbling(self.llm, prompt)\n",
    "        if '```' in res:\n",
    "            regex = parsing_regex['llama3']\n",
    "        else:\n",
    "            regex = parsing_regex['openai']\n",
    "        code_blocks = re.findall(regex, res, flags=re.DOTALL)\n",
    "        return code_blocks\n",
    "\n",
    "    def execute_code(self, code_blocks, **input_variables):\n",
    "        for variable_name, variable_value in input_variables.items():\n",
    "            globals()[variable_name] = variable_value\n",
    "        for code in code_blocks:\n",
    "            print(\"-------------Executing\", code)\n",
    "            exec(code, globals())    \n",
    "\n",
    "    def pandas_dataframe_validation(self, pdf):\n",
    "        try:\n",
    "            assert type(pdf) == pd.DataFrame\n",
    "        except:\n",
    "            raise PandasDataFrameValidationException(\"Function output is not a pandas dataframe\")\n",
    "    def pandas_columns_integers_validation(self, pdf):\n",
    "        try:\n",
    "            pdf.astype(int)\n",
    "        except:\n",
    "            raise PandasColumnsIntegerValidationException(\"Not all the dataframe's columns are numerical\")\n",
    "    def target_feature_in_dataframe(self, pdf):\n",
    "        try:\n",
    "            assert self.target_feature in pdf.columns.tolist()\n",
    "        except:\n",
    "            raise TargetFeatureInDataFrameValidationException(f\"Target feature '{self.target_feature}' is not in the dataframe\")\n",
    "    def target_feature_is_binary(self, pdf):\n",
    "        try:\n",
    "            assert pdf[self.target_feature].tolist() == original_value\n",
    "        except:\n",
    "            raise TargetFeatureIsBinaryValidationException(f\"Target feature '{self.target_feature}' was altered\")\n",
    "\n",
    "    def correct_function_signature(self, function, input_variables):\n",
    "        try:\n",
    "            assert list(function.__code__.co_varnames)[:function.__code__.co_argcount] == list(input_variables.keys())\n",
    "        except:\n",
    "            raise FunctionDoesNotMatchSignatureValidationException(f\"Function does not match signature {list(function.__code__.co_varnames)[:function.__code__.co_argcount]} != {list(input_variables.keys())}\")\n",
    "    def manage_error(self, retry_prompt, initial_prompt, error_count, retry_attempts, retry_limit=-1, self_debug_attempts=-1):\n",
    "        if retry_limit == -1:\n",
    "            retry_limit=self.max_retry_attempts\n",
    "        if self_debug_attempts == -1:\n",
    "            self_debug_attempts = self.max_self_debug_attempts\n",
    "        error_count += 1\n",
    "        if error_count >= self_debug_attempts:\n",
    "            print(\"Failed self debug\")\n",
    "            prompt = initial_prompt\n",
    "            retry_attempts += 1\n",
    "            error_count = 0\n",
    "            print(\"Retry attempt: \", retry_attempts)\n",
    "            if retry_attempts >= retry_limit:\n",
    "                raise MaxRetriesExceededError()\n",
    "        else:\n",
    "            prompt = retry_prompt\n",
    "        return prompt, error_count, retry_attempts\n",
    "\n",
    "    def validate_step(self,step_output, step_validations):\n",
    "        for validation in step_validations:\n",
    "            print('---VALIDATION---')\n",
    "            validation(step_output)\n",
    "            \n",
    "    def run_step(self, step_prompt, step_name, parent_node, step_validations = None, **input_variables):\n",
    "        completed = False\n",
    "        error_count = self.max_self_debug_attempts\n",
    "        retry_attempts = 0\n",
    "        prompt = self.init_template + step_prompt+ f\"\\nDO NOT CALL THE FUNCTIONS. \\n Each function should complete the task independently and covers all bullet points \\n function names should be in the format of function_1, ..., function_{self.child_count}\"\n",
    "        self.prompt = prompt\n",
    "        step_outputs = []\n",
    "        succeeded = True\n",
    "        if type(results_tree[parent_node].data) != dict:\n",
    "            results_tree[parent_node].data = {}\n",
    "        while not completed:\n",
    "            code_blocks = self.predict_prompt_and_parse(prompt)  \n",
    "            \n",
    "            try:\n",
    "                print(f\"-----Given code block------:\\n {code_blocks} \\n ------------\")\n",
    "                \n",
    "                if len(code_blocks) == 0:\n",
    "                    raise MissingCodeValidationException()\n",
    "                self.execute_code(code_blocks, **input_variables)\n",
    "                if len(code_blocks) == 1:\n",
    "                    code_blocks = re.findall(r'(def function_\\d.*?)(?:\\n\\n|```|$)', code_blocks[0], flags=re.DOTALL)\n",
    "                \n",
    "                for i in range(1,self.child_count+1):\n",
    "                    function = eval(f'function_{i}')\n",
    "                    self.correct_function_signature(function, input_variables)\n",
    "                    \n",
    "                for i in range(1,self.child_count+1):\n",
    "                    step_outputs.append(self.execute_function(eval(f\"function_{i}\"), code_blocks[i-1], parent_node, i, step_name, step_validations, **input_variables))\n",
    "                    \n",
    "                if self.child_count / 2 < len([output for output in step_outputs if type(output) == type(None)]):\n",
    "                    raise FailedGeneratingFunction()\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    results_tree[parent_node].data['child_generation_error:' + type(e).__name__] = results_tree[parent_node].data.get(type(e).__name__,0) + 1\n",
    "                    print(\"Error:\", e, \"------\")\n",
    "                    retry_prompt = \"\"\n",
    "                    initial_prompt = prompt\n",
    "                    prompt, error_count, retry_attempts = self.manage_error(retry_prompt, initial_prompt, error_count, retry_attempts, self_debug_attempts = 1)\n",
    "                except Exception as e:\n",
    "                    succeeded = False\n",
    "                    completed = True\n",
    "                    \n",
    "            else:\n",
    "                completed = True\n",
    "        for i in range(1, self.child_count+1):\n",
    "            node_name = f\"{parent_node}: {step_name}_{i}\"\n",
    "            if node_name not in results_tree:\n",
    "                results_tree.create_node(f\"{step_name}_{i}\", node_name, parent=parent_node, data={\"succeeded\":False, 'succeeded_on_self_debug': False})\n",
    "        results_tree[parent_node].data['child_retry_attempts'] = retry_attempts        \n",
    "        results_tree[parent_node].data['child_generation_succeeded'] = succeeded\n",
    "        \n",
    "        return step_outputs       \n",
    "        \n",
    "        \n",
    "    def execute_function(self, function, function_code, parent_node, child_num, step_name, step_validations, **input_variables):\n",
    "        \n",
    "        function_name = function.__name__\n",
    "        completed = False\n",
    "        retry_attempts = 0\n",
    "        error_count = 0\n",
    "        code_error_count = 0\n",
    "        should_execute_code = False\n",
    "        succeeded = True\n",
    "        attempted_self_debug = False\n",
    "        node_data = {}\n",
    "        while not completed:\n",
    "            try:\n",
    "                if should_execute_code:\n",
    "                    function_code = \"\\n\".join(code_blocks)\n",
    "                    self.execute_code(code_blocks, **input_variables)\n",
    "                    function = eval(function_name)\n",
    "                    \n",
    "                step_output = function(**input_variables)\n",
    "                if step_validations:\n",
    "                    self.validate_step(step_output, step_validations)\n",
    "            except Exception as e:\n",
    "                node_data[type(e).__name__] = node_data.get(type(e).__name__,0) + 1\n",
    "                node_data['number_of_self_debug'] = node_data.get('number_of_self_debug', 0) + 1\n",
    "                print(\"Error\", e, '----')\n",
    "                retry_prompt = f\"{self.prompt} + \\n You provided the code:\\n ```Python\\n{function_code}```. I received the error {type(e)}:{e}, can you regenerate? Call the function in the same name. \\nDO NOT CALL THE FUNCTIONS. \\n The function names should be in the format of function_1, ..., function_{self.child_count}\"\n",
    "                initial_prompt = f\"{self.prompt} + \\n You provided the code:\\n ```Python\\n{function_code}```. I have problems with it, can you generate different code that does the same thing? call the function in the same name. \\n DO NOT CALL THE FUNCTIONS. \\n function names should be in the format of function_1, ..., function_{self.child_count}\"\n",
    "                attempted_self_debug = True\n",
    "                try:\n",
    "                    prompt, error_count, retry_attempts = self.manage_error(retry_prompt, initial_prompt, error_count, retry_attempts, retry_limit=2)\n",
    "                    code_blocks = self.predict_prompt_and_parse(prompt)  \n",
    "                    should_execute_code = True\n",
    "                except Exception as e:\n",
    "                    step_output = None\n",
    "                    succeeded = False\n",
    "                    completed = True\n",
    "                \n",
    "            else:\n",
    "                completed = True\n",
    "        node_data['succeeded_on_self_debug'] =  succeeded & attempted_self_debug\n",
    "        node_data['succeeded'] = succeeded\n",
    "        node_name = f\"{parent_node}: {step_name}_{child_num}\"\n",
    "        if node_name not in results_tree:\n",
    "            results_tree.create_node(f\"{step_name}_{child_num}\", node_name, parent=parent_node, data=node_data)\n",
    "        else:\n",
    "            for key in list(node_data.keys()):\n",
    "                if key in list(results_tree[node_name].data.keys()):\n",
    "                    results_tree[node_name].data[key] += node_data[key]\n",
    "                else:\n",
    "                    results_tree[node_name].data[key] = node_data[key]\n",
    "                    \n",
    "            \n",
    "        return step_output\n",
    "        \n",
    "    \n",
    "    def llm_exploration(self, pdf, parent_name):\n",
    "        self.exploration_string = self.run_step(self.read_prompt('exploration'), \"exploration\", parent_name, pdf=pdf)\n",
    "        exploration_strings = [string[:4096] for string in self.exploration_string if string != None]\n",
    "        print(\"Finished exploration\", exploration_strings)\n",
    "        return exploration_strings\n",
    "\n",
    "    def llm_preprocessing(self, exploration_string, pdf, target_feature, parent_name):\n",
    "        self.preprocessed_data_list = self.run_step(self.read_prompt('data_preprocessing').format(exploration_string)\n",
    "                                               + '\\nreturn a pandas dataframe', \"preprocessing\", parent_name,\n",
    "                                               step_validations=[self.pandas_dataframe_validation, self.pandas_columns_integers_validation,\n",
    "                                                                self.target_feature_in_dataframe, self.target_feature_is_binary] ,pdf = pdf)\n",
    "        print(\"Finished preprocessing\")\n",
    "        Xs= []\n",
    "        ys = []\n",
    "        for preprocessed_data in self.preprocessed_data_list:\n",
    "            if type(preprocessed_data) != type(None):\n",
    "                if type(preprocessed_data) == pd.DataFrame and not preprocessed_data.empty:\n",
    "                    Xs.append(preprocessed_data.drop(columns=[target_feature]))\n",
    "                    ys.append(preprocessed_data[target_feature])\n",
    "        return Xs,ys\n",
    "\n",
    "    def llm_training(self, X_train, y_train, parent_name):\n",
    "        self.best_model = self.run_step(self.read_prompt('model_training'), \"training\", parent_name,\n",
    "                                        step_validations=[predict_in_model_object],\n",
    "                                        X_train=X_train, y_train=y_train)\n",
    "        print(\"Finished training\", self.best_model)\n",
    "        return [model for model in self.best_model if type(model) != type(None)]\n",
    "\n",
    "    def run(self):\n",
    "        exploration_strings = self.llm_exploration(self.pdf, parent_name=self.base_parent_name)\n",
    "        best_model = None\n",
    "        best_score = 0\n",
    "        for i, exploration_string in enumerate(exploration_strings):\n",
    "            exploration_parent_name = f\"{self.base_parent_name}: exploration_{i+1}\"\n",
    "            Xs, ys = self.llm_preprocessing(exploration_string, self.pdf, self.target_feature, parent_name=exploration_parent_name)       \n",
    "            for j, (X, y) in enumerate(zip(Xs, ys)):\n",
    "                preprocessing_parent_name = f\"{exploration_parent_name}: preprocessing_{j+1}\"\n",
    "                self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X,y,test_size=0.25, random_state=42)\n",
    "                models = self.llm_training(self.X_train, self.y_train, parent_name=preprocessing_parent_name)\n",
    "                for k, current_model in enumerate(models):\n",
    "                    current_score = self.evaluate(current_model, self.X_test, self.y_test)\n",
    "                    results_tree[f\"{preprocessing_parent_name}: training_{k+1}\"].data['score'] = current_score\n",
    "                    print(f\"{current_score} accuracy score\")\n",
    "                    if self.metric == 'classification':\n",
    "                        if current_score > best_score:\n",
    "                            best_score = current_score\n",
    "                            best_model = current_model\n",
    "                    else:\n",
    "                        if current_score < best_score:\n",
    "                            best_score = current_score\n",
    "                            best_model = current_model\n",
    "        results_tree[self.base_parent_name].data['best_score'] = best_score\n",
    "        results_tree[self.base_parent_name].data['best_model'] = best_model\n",
    "        print(f\"Best score:{best_score}, best_model:{best_model}\")\n",
    "        return best_model\n",
    "            \n",
    "        \n",
    "    def evaluate(self, llm_model, X_test, y_test):\n",
    "        if self.metric == 'classification':\n",
    "            y_pred = llm_model.predict(X_test)\n",
    "            model_score = accuracy_score(y_test, y_pred)\n",
    "            return model_score\n",
    "        else:\n",
    "            y_pred = llm_model.predict(X_test)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './prompts/flow_prompts/tot_prompts/exploration.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m pdf_temp \u001b[38;5;241m=\u001b[39m pdf\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      7\u001b[0m AK \u001b[38;5;241m=\u001b[39m AutoKaggleToT(llm, llm_type, dataset_name, pdf_temp, dataset_info\u001b[38;5;241m=\u001b[39mdataset_info[dataset_name], metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m target_feature \u001b[38;5;241m=\u001b[39m target_feature, max_self_debug_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_retry_attempts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, child_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mAK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 241\u001b[0m, in \u001b[0;36mAutoKaggleToT.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 241\u001b[0m     exploration_strings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_exploration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_parent_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[13], line 213\u001b[0m, in \u001b[0;36mAutoKaggleToT.llm_exploration\u001b[1;34m(self, pdf, parent_name)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllm_exploration\u001b[39m(\u001b[38;5;28mself\u001b[39m, pdf, parent_name):\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_step(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexploration\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexploration\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent_name, pdf\u001b[38;5;241m=\u001b[39mpdf)\n\u001b[0;32m    214\u001b[0m     exploration_strings \u001b[38;5;241m=\u001b[39m [string[:\u001b[38;5;241m4096\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m string \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_string \u001b[38;5;28;01mif\u001b[39;00m string \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished exploration\u001b[39m\u001b[38;5;124m\"\u001b[39m, exploration_strings)\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mAutoKaggleToT.read_prompt\u001b[1;34m(self, prompt_name)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt_name):\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./prompts/flow_prompts/tot_prompts/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m prompt_file:\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m prompt_file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './prompts/flow_prompts/tot_prompts/exploration.txt'"
     ]
    }
   ],
   "source": [
    "results_tree = Tree()\n",
    "results_tree.create_node('root', 'root')\n",
    "for llm_type, llm in llms:\n",
    "    dataset_name, target_feature, pdf = get_dataset()  #  compressed to a function, so I can now use it.\n",
    "    original_value = pdf[target_feature].tolist()\n",
    "    pdf_temp = pdf.copy()\n",
    "    AK = AutoKaggleToT(llm, llm_type, dataset_name, pdf_temp, dataset_info=dataset_info[dataset_name], metric='regression',\n",
    "    target_feature = target_feature, max_self_debug_attempts=2, max_retry_attempts=5, child_count=2)\n",
    "    AK.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root': Node(tag=root, identifier=root, data=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tree.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tree.nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
